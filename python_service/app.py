"""
Python Microservice for Pandas DataFrame Operations
This is the "Calculator" - the source of truth for Excel/CSV data
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import pandas as pd
import numpy as np
import json
import io
import base64
from typing import Dict, Any, List
import traceback
import os

app = Flask(__name__)
CORS(app)

# In-memory DataFrame cache (keyed by document_id)
dataframe_cache: Dict[str, pd.DataFrame] = {}
# In-memory Summary cache (keyed by document_id)



@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({"status": "healthy", "service": "pandas-calculator"})


@app.route('/load-dataframe', methods=['POST'])
def load_dataframe():
    """
    Load Excel/CSV into Pandas DataFrame (source of truth)
    
    Request body:
    {
        "document_id": "uuid",
        "file_content": "base64-encoded file",
        "file_type": "csv" | "xlsx" | "xls"
    }
    """
    try:
        data = request.json
        document_id = data.get('document_id')
        file_content_b64 = data.get('file_content')
        file_type = data.get('file_type', '').lower()
        
        if not all([document_id, file_content_b64, file_type]):
            return jsonify({"error": "Missing required fields"}), 400
        
        # Decode base64 content
        file_bytes = base64.b64decode(file_content_b64)
        
        extracted_summary = None

        # Load into Pandas DataFrame based on file type
        if file_type == 'csv':
            df = pd.read_csv(io.BytesIO(file_bytes))
        elif file_type in ['xlsx', 'xls']:
            # Standard load without extraction logic
            df = pd.read_excel(io.BytesIO(file_bytes))
        else:
            return jsonify({"error": f"Unsupported file type: {file_type}"}), 400
        
        # Cache the DataFrame
        dataframe_cache[document_id] = df
        
        # Get schema information
        schema = get_dataframe_schema(df)
        
        # Convert sample data and replace NaN/Infinity with None for JSON serialization
        sample_df = df.head(10).replace([np.nan, np.inf, -np.inf], None)
        
        return jsonify({
            "success": True,
            "document_id": document_id,
            "rows": len(df),
            "columns": list(df.columns),
            "schema": schema,
            "sample_data": sample_df.to_dict('records'),
            "extracted_summary": extracted_summary
        })
        
    except Exception as e:
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500


@app.route('/execute-pandas', methods=['POST'])
def execute_pandas():
    """
    Execute Pandas operations (the "calculator")
    
    Request body:
    {
        "document_id": "uuid",
        "operation": "pandas operation code",
        "safe_mode": true
    }
    """
    try:
        data = request.json
        document_id = data.get('document_id')
        operation = data.get('operation')
        safe_mode = data.get('safe_mode', True)
        
        if not document_id or not operation:
            return jsonify({"error": "Missing document_id or operation"}), 400
        
        # Get DataFrame from cache
        if document_id not in dataframe_cache:
            return jsonify({"error": "DataFrame not loaded. Call /load-dataframe first"}), 404
        
        df = dataframe_cache[document_id]
        
        # Security: Validate operation in safe mode
        if safe_mode:
            forbidden = ['import', 'exec', 'eval', '__', 'open', 'file', 'os.', 'sys.', 'subprocess']
            if any(keyword in operation.lower() for keyword in forbidden):
                return jsonify({"error": "Forbidden operation detected"}), 403
        
        # Create safe execution context
        namespace = {
            'df': df,
            'pd': pd,
            'np': np,
            'result': None
        }
        
        # Execute the Pandas operation
        exec(operation, namespace)
        result = namespace.get('result')
        
        # Convert result to JSON-serializable format
        result_data = serialize_result(result)
        
        return jsonify({
            "success": True,
            "result": result_data,
            "operation": operation
        })
        
    except Exception as e:
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500


@app.route('/query-natural', methods=['POST'])
def query_natural():
    """
    Natural language query endpoint
    This returns structured data for the LLM to interpret
    
    Request body:
    {
        "document_id": "uuid",
        "pandas_code": "generated by LLM"
    }
    """
    try:
        data = request.json
        document_id = data.get('document_id')
        pandas_code = data.get('pandas_code')
        
        if not document_id or not pandas_code:
            return jsonify({"error": "Missing required fields"}), 400
        
        # Get DataFrame
        if document_id not in dataframe_cache:
            return jsonify({"error": "DataFrame not loaded"}), 404
        
        df = dataframe_cache[document_id]
        
        # Setup execution context
        namespace = {
            'df': df,
            'pd': pd,
            'np': np,
            'result': None
        }
        
        # Execute code
        exec(pandas_code, namespace)
        result = namespace['result']
        
        # Serialize result
        result_data = serialize_result(result)
        
        return jsonify({
            "success": True,
            "result": result_data,
            "code_executed": pandas_code
        })
        
    except Exception as e:
        return jsonify({
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500


@app.route('/describe-dataframe', methods=['POST'])
def describe_dataframe():
    """Get statistical description of DataFrame"""
    try:
        data = request.json
        document_id = data.get('document_id')
        
        if document_id not in dataframe_cache:
            return jsonify({"error": "DataFrame not loaded"}), 404
        
        df = dataframe_cache[document_id]
        
        # Get comprehensive statistics (replace NaN for JSON compatibility)
        description_df = df.describe().replace([np.nan, np.inf, -np.inf], None)
        sample_df = df.head(20).replace([np.nan, np.inf, -np.inf], None)
        
        stats = {
            "shape": df.shape,
            "columns": list(df.columns),
            "dtypes": df.dtypes.astype(str).to_dict(),
            "description": description_df.to_dict(),
            "null_counts": df.isnull().sum().to_dict(),
            "unique_counts": df.nunique().to_dict(),
            "sample_rows": sample_df.to_dict('records')
        }
        
        return jsonify({
            "success": True,
            "statistics": stats
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500





def get_dataframe_schema(df: pd.DataFrame) -> List[Dict[str, Any]]:
    """Extract schema information from DataFrame"""
    schema = []
    for col in df.columns:
        dtype = str(df[col].dtype)
        null_count = int(df[col].isnull().sum())
        unique_count = int(df[col].nunique())
        
        # Sample values
        sample_values = df[col].dropna().head(3).tolist()
        
        schema.append({
            "column": col,
            "dtype": dtype,
            "null_count": null_count,
            "unique_count": unique_count,
            "sample_values": sample_values
        })
    
    return schema


def serialize_result(result):
    """Convert various result types to JSON-serializable format"""
    if result is None:
        return None
    
    # DataFrame
    if isinstance(result, pd.DataFrame):
        # Replace NaN/Inf with None for JSON compatibility
        clean_df = result.replace([np.nan, np.inf, -np.inf], None)
        return {
            "type": "dataframe",
            "data": clean_df.to_dict('records'),
            "columns": list(result.columns),
            "shape": result.shape
        }
    
    # Series
    if isinstance(result, pd.Series):
        # Replace NaN/Inf with None for JSON compatibility
        clean_series = result.replace([np.nan, np.inf, -np.inf], None)
        return {
            "type": "series",
            "data": clean_series.to_dict(),
            "name": result.name
        }
    
    # Numpy types
    if isinstance(result, (np.integer, np.floating)):
        return {
            "type": "number",
            "value": float(result)
        }
    
    # Dict
    if isinstance(result, dict):
        return {
            "type": "dict",
            "data": result
        }
    
    # List
    if isinstance(result, list):
        return {
            "type": "list",
            "data": result
        }
    
    # Primitive types
    if isinstance(result, (int, float, str, bool)):
        return {
            "type": type(result).__name__,
            "value": result
        }
    
    # Default: try to convert to string
    return {
        "type": "string",
        "value": str(result)
    }


if __name__ == '__main__':
    print("üêç Starting Pandas Calculator Service...")
    print("üìä This is the SOURCE OF TRUTH for Excel/CSV data")
    port = int(os.environ.get("PORT", 5001))
    debug = os.environ.get("FLASK_ENV", "development") == "development"
    app.run(host='0.0.0.0', port=port, debug=debug)
